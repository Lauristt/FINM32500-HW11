{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I run the model on google colab using t100 gpu thus i have to submit the .ipynb version"
      ],
      "metadata": {
        "id": "MleLVO0xHXli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oYtQ5bMIMBI",
        "outputId": "f64d6b72-b037-4104-db8d-177bdaf4689f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root = os.path.join(os.getcwd(),'drive','MyDrive','train_model')\n",
        "os.listdir(root)"
      ],
      "metadata": {
        "id": "4mHrIJC8HzDq",
        "outputId": "3f4ca389-db37-4960-a3ad-566e0b8bc552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['processed_data.csv',\n",
              " 'train_model.ipynb',\n",
              " 'features_config.json',\n",
              " 'model_params.json']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv = os.path.join(root,'processed_data.csv')\n",
        "features_cfg = os.path.join(root,'features_config.json')\n",
        "model_cfg = os.path.join(root,'model_params.json')\n",
        "\n",
        "# output\n",
        "# xgb path will be handled in the xgb fold-wise processing\n",
        "save_lr_pkl = os.path.join(root,'model','LogisticRegression.pkl')\n",
        "save_rf_pkl = os.path.join(root,'model','RandomForestClassifier.pkl')\n",
        "\n",
        "save_inference_csv = os.path.join(root,'test_data_with_actuals.csv')"
      ],
      "metadata": {
        "id": "cmNumRswIYau"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import joblib\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "except ImportError:\n",
        "    XGBClassifier = None\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "pI0PxDnGHohe"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " I wrote a 5-fold model"
      ],
      "metadata": {
        "id": "h_UlJHXoKzOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models_with_5folds():\n",
        "    print(\"Loading processed data and configuration...\")\n",
        "    try:\n",
        "        df = pd.read_csv(data_csv)\n",
        "        with open(features_cfg, 'r') as f:\n",
        "            feat_config = json.load(f)\n",
        "        with open(model_cfg, 'r') as f:\n",
        "            model_params = json.load(f)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Run feature_engineering.py first.\")\n",
        "        return\n",
        "\n",
        "    features = feat_config['features']\n",
        "    label = feat_config['label']\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[label]\n",
        "\n",
        "    # no-shuffle split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Logistic Regression\n",
        "    if \"LogisticRegression\" in model_params:\n",
        "        print(\"Training Logistic Regression...\")\n",
        "        lr_params = model_params[\"LogisticRegression\"]\n",
        "        lr = LogisticRegression(**lr_params)\n",
        "        lr.fit(X_train, y_train)\n",
        "        joblib.dump(lr, save_lr_pkl)\n",
        "        models[\"LogisticRegression\"] = lr\n",
        "\n",
        "    # Random Forest\n",
        "    if \"RandomForestClassifier\" in model_params:\n",
        "        print(\"Training Random Forest...\")\n",
        "        rf_params = model_params[\"RandomForestClassifier\"]\n",
        "        rf = RandomForestClassifier(**rf_params, random_state=42)\n",
        "        rf.fit(X_train, y_train)\n",
        "        joblib.dump(lr, save_rf_pkl)\n",
        "        models[\"RandomForestClassifier\"] = rf\n",
        "\n",
        "    #5-fold CV\n",
        "    if \"XGBClassifier\" in model_params:\n",
        "        if XGBClassifier:\n",
        "            print(\"Training XGBoost with 5-fold CV...\")\n",
        "\n",
        "            xgb_params = model_params[\"XGBClassifier\"]\n",
        "            kf = KFold(n_splits=5, shuffle=False)\n",
        "\n",
        "            fold_models = []\n",
        "            fold_accuracies = []\n",
        "\n",
        "            for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "                print(f\"  Fold {fold+1}/5\")\n",
        "\n",
        "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "                xgb = XGBClassifier(\n",
        "                    **xgb_params,\n",
        "                    use_label_encoder=False,\n",
        "                    eval_metric='logloss',\n",
        "                    random_state=42\n",
        "                )\n",
        "                xgb.fit(X_tr, y_tr)\n",
        "\n",
        "                # validation accuracy\n",
        "                val_pred = xgb.predict(X_val)\n",
        "                val_acc = accuracy_score(y_val, val_pred)\n",
        "                print(f\"    Fold {fold+1} accuracy: {val_acc:.4f}\")\n",
        "\n",
        "                fold_models.append(xgb)\n",
        "                fold_accuracies.append(val_acc)\n",
        "                joblib.dump(xgb,os.path.join(root, 'model', f'XGBClassifier_fold{fold+1}.pkl'))\n",
        "\n",
        "            print(f\"XGBoost 5-fold mean accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "\n",
        "            # save the last model\n",
        "            models[\"XGBClassifier\"] = fold_models[-1]\n",
        "\n",
        "        else:\n",
        "            print(\"Skipping XGBoost. Cannot import XGBClassifier\")\n",
        "\n",
        "    # Evaluation\n",
        "    best_model = None\n",
        "    best_acc = 0\n",
        "    results_summary = []\n",
        "\n",
        "    print(\"Model Evaluation...\")\n",
        "    for name, model in models.items():\n",
        "        preds = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "\n",
        "        results_summary.append({'Model': name, 'Accuracy': acc})\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_model = model\n",
        "\n",
        "    if best_model:\n",
        "        joblib.dump(best_model, save_pkl)\n",
        "        print(f\"\\nBest model ({type(best_model).__name__}) saved to the corresponding path.\")\n",
        "\n",
        "    test_indices = X_test.index\n",
        "    test_data_export = df.iloc[test_indices].copy()\n",
        "    test_data_export.to_csv(save_inference_csv, index=False)"
      ],
      "metadata": {
        "id": "Kh4fSGS8KGDp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_models_with_5folds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyrcEADgKS6E",
        "outputId": "7442dea8-0dfe-4c9f-da64-d2ecd7142e42"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading processed data and configuration...\n",
            "Training samples: 984, Test samples: 246\n",
            "Training Logistic Regression...\n",
            "Training Random Forest...\n",
            "Training XGBoost with 5-fold CV...\n",
            "  Fold 1/5\n",
            "    Fold 1 accuracy: 0.4772\n",
            "  Fold 2/5\n",
            "    Fold 2 accuracy: 0.5279\n",
            "  Fold 3/5\n",
            "    Fold 3 accuracy: 0.5431\n",
            "  Fold 4/5\n",
            "    Fold 4 accuracy: 0.5431\n",
            "  Fold 5/5\n",
            "    Fold 5 accuracy: 0.4847\n",
            "XGBoost 5-fold mean accuracy: 0.5152\n",
            "Model Evaluation...\n",
            "LogisticRegression Accuracy: 0.5041\n",
            "RandomForestClassifier Accuracy: 0.5041\n",
            "XGBClassifier Accuracy: 0.5447\n",
            "\n",
            "Best model (XGBClassifier) saved to best_model.pkl\n"
          ]
        }
      ]
    }
  ]
}